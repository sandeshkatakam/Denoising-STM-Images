{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bdf199",
   "metadata": {},
   "source": [
    "# NeuralODE model for denoising STM Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab0173",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fea522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import numpy as jnp\n",
    "from flax import linen as fnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742ebd6",
   "metadata": {},
   "source": [
    "## Data preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2d261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6d912e",
   "metadata": {},
   "source": [
    "## Data Loading Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba730a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "PATH = 'datasets/'\n",
    "BATCH_SIZE = 12\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "\n",
    "def read_train_data():\n",
    "    x_files = [f for f in glob.glob(PATH + \"train/*.jpg\", recursive=True)]\n",
    "    y_files = [f for f in glob.glob(PATH + \"mask/*.jpg\", recursive=True)]\n",
    "\n",
    "    def read_image(x_filename, y_filename):\n",
    "        x_image_string = tf.io.read_file(x_filename)\n",
    "        y_image_string = tf.io.read_file(y_filename)\n",
    "\n",
    "        x_image_decoded = tf.image.decode_jpeg(x_image_string, channels=3)\n",
    "        y_image_decoded = tf.image.decode_jpeg(y_image_string, channels=1)\n",
    "\n",
    "        x_image_resized = tf.image.resize(x_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "        y_image_resized = tf.image.resize(y_image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "        x_image_norm = x_image_resized / 255\n",
    "        y_image_norm = y_image_resized / 255\n",
    "\n",
    "        return x_image_norm, y_image_norm\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
    "\n",
    "    dataset = dataset.map(read_image).shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def read_predict_data():\n",
    "    file_path = 'predict/pre.jpg'\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image_decoded = tf.image.decode_jpeg(image, channels=3)\n",
    "    image_resized = tf.image.resize(image_decoded, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image_norm = image_resized / 255\n",
    "\n",
    "    return image_norm\n",
    "\n",
    "\n",
    "def save_image(image):\n",
    "    file_path = 'predict/result.jpg'\n",
    "    image = image * 255\n",
    "\n",
    "    encode_image = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "    with open(file_path, 'wb') as fd:\n",
    "        fd.write(encode_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317d814",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577d20d",
   "metadata": {},
   "source": [
    "### U-Net Architecture in JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c24861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(fnn.Module):\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, x):\n",
    "        z1 = fnn.Conv(self.features, kernel_size=(3, 3))(x)\n",
    "        z1 = fnn.relu(z1)\n",
    "        z1 = fnn.Conv(self.features, kernel_size=(3, 3))(z1)\n",
    "        z1 = fnn.BatchNorm(use_running_average=not self.training)(z1)\n",
    "        z1 = fnn.relu(z1)\n",
    "        z1_pool = fnn.max_pool(z1, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        z2 = fnn.Conv(self.features * 2, kernel_size=(3, 3))(z1_pool)\n",
    "        z2 = fnn.relu(z2)\n",
    "        z2 = fnn.Conv(self.features * 2, kernel_size=(3, 3))(z2)\n",
    "        z2 = fnn.BatchNorm(use_running_average=not self.training)(z2)\n",
    "        z2 = fnn.relu(z2)\n",
    "        z2_pool = fnn.max_pool(z2, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        z3 = fnn.Conv(self.features * 4, kernel_size=(3, 3))(z2_pool)\n",
    "        z3 = fnn.relu(z3)\n",
    "        z3 = fnn.Conv(self.features * 4, kernel_size=(3, 3))(z3)\n",
    "        z3 = fnn.BatchNorm(use_running_average=not self.training)(z3)\n",
    "        z3 = fnn.relu(z3)\n",
    "        z3_pool = fnn.max_pool(z3, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        z4 = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z3_pool)\n",
    "        z4 = fnn.relu(z4)\n",
    "        z4 = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z4)\n",
    "        z4 = fnn.BatchNorm(use_running_average=not self.training)(z4)\n",
    "        z4 = fnn.relu(z4)\n",
    "        z4_dropout = fnn.Dropout(0.5, deterministic=False)(z4)\n",
    "        z4_pool = fnn.max_pool(z4_dropout, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        z5 = fnn.Conv(self.features * 16, kernel_size=(3, 3))(z4_pool)\n",
    "        z5 = fnn.relu(z5)\n",
    "        z5 = fnn.Conv(self.features * 16, kernel_size=(3, 3))(z5)\n",
    "        z5 = fnn.BatchNorm(use_running_average=not self.training)(z5)\n",
    "        z5 = fnn.relu(z5)\n",
    "        z5_dropout = fnn.Dropout(0.5, deterministic=False)(z5)\n",
    "\n",
    "        return z1, z2, z3, z4_dropout, z5_dropout\n",
    "\n",
    "\n",
    "class Decoder(fnn.Module):\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, z1, z2, z3, z4_dropout, z5_dropout):\n",
    "        z6_up = jax.image.resize(z5_dropout, shape=(z5_dropout.shape[0], z5_dropout.shape[1] * 2, z5_dropout.shape[2] * 2, z5_dropout.shape[3]),\n",
    "                                 method='nearest')\n",
    "        z6 = fnn.Conv(self.features * 8, kernel_size=(2, 2))(z6_up)\n",
    "        z6 = fnn.relu(z6)\n",
    "        z6 = jnp.concatenate([z4_dropout, z6], axis=3)\n",
    "        z6 = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z6)\n",
    "        z6 = fnn.relu(z6)\n",
    "        z6 = fnn.Conv(self.features * 8, kernel_size=(3, 3))(z6)\n",
    "        z6 = fnn.BatchNorm(use_running_average=not self.training)(z6)\n",
    "        z6 = fnn.relu(z6)\n",
    "\n",
    "        z7_up = jax.image.resize(z6, shape=(z6.shape[0], z6.shape[1] * 2, z6.shape[2] * 2, z6.shape[3]),\n",
    "                                 method='nearest')\n",
    "        z7 = fnn.Conv(self.features * 4, kernel_size=(2, 2))(z7_up)\n",
    "        z7 = fnn.relu(z7)\n",
    "        z7 = jnp.concatenate([z3, z7], axis=3)\n",
    "        z7 = fnn.Conv(self.features * 4, kernel_size=(3, 3))(z7)\n",
    "        z7 = fnn.relu(z7)\n",
    "        z7 = fnn.Conv(self.features * 4, kernel_size=(3, 3))(z7)\n",
    "        z7 = fnn.BatchNorm(use_running_average=not self.training)(z7)\n",
    "        z7 = fnn.relu(z7)\n",
    "\n",
    "        z8_up = jax.image.resize(z7, shape=(z7.shape[0], z7.shape[1] * 2, z7.shape[2] * 2, z7.shape[3]),\n",
    "                                 method='nearest')\n",
    "        z8 = fnn.Conv(self.features * 2, kernel_size=(2, 2))(z8_up)\n",
    "        z8 = fnn.relu(z8)\n",
    "        z8 = jnp.concatenate([z2, z8], axis=3)\n",
    "        z8 = fnn.Conv(self.features * 2, kernel_size=(3, 3))(z8)\n",
    "        z8 = fnn.relu(z8)\n",
    "        z8 = fnn.Conv(self.features * 2, kernel_size=(3, 3))(z8)\n",
    "        z8 = fnn.BatchNorm(use_running_average=not self.training)(z8)\n",
    "        z8 = fnn.relu(z8)\n",
    "\n",
    "        z9_up = jax.image.resize(z8, shape=(z8.shape[0], z8.shape[1] * 2, z8.shape[2] * 2, z8.shape[3]),\n",
    "                                 method='nearest')\n",
    "        z9 = fnn.Conv(self.features, kernel_size=(2, 2))(z9_up)\n",
    "        z9 = fnn.relu(z9)\n",
    "        z9 = jnp.concatenate([z1, z9], axis=3)\n",
    "        z9 = fnn.Conv(self.features, kernel_size=(3, 3))(z9)\n",
    "        z9 = fnn.relu(z9)\n",
    "        z9 = fnn.Conv(self.features, kernel_size=(3, 3))(z9)\n",
    "        z9 = fnn.BatchNorm(use_running_average=not self.training)(z9)\n",
    "        z9 = fnn.relu(z9)\n",
    "\n",
    "        y = fnn.Conv(1, kernel_size=(1, 1))(z9)\n",
    "        y = fnn.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNet(fnn.Module):\n",
    "    features: int = 64\n",
    "    training: bool = True\n",
    "\n",
    "    @fnn.compact\n",
    "    def __call__(self, x):\n",
    "        z1, z2, z3, z4_dropout, z5_dropout = Encoder(self.training)(x)\n",
    "        y = Decoder(self.training)(z1, z2, z3, z4_dropout, z5_dropout)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51fd4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc2678c",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac251b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.training import checkpoints\n",
    "\n",
    "from models import UNet\n",
    "from data import read_train_data, read_predict_data, save_image\n",
    "\n",
    "CKPT_DIR = 'ckpts'\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "\n",
    "class CustomTrainState(TrainState):\n",
    "    batch_stats: dict\n",
    "\n",
    "    def apply_fn_with_bn(self, *args, is_training, **nargs):\n",
    "        output, mutated_vars = self.apply_fn(*args, **nargs,\n",
    "                                             mutable=[\"batch_stats\"], rngs={'dropout': jax.random.PRNGKey(2)})\n",
    "        new_batch_stats = mutated_vars[\"batch_stats\"]\n",
    "        return output, new_batch_stats\n",
    "\n",
    "    def update_batch_stats(self, new_batch_stats):\n",
    "        return self.replace(batch_stats=new_batch_stats)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = jnp.ravel(y_true)\n",
    "    y_pred = jnp.ravel(y_pred)\n",
    "    intersection = jnp.sum(y_true * y_pred)\n",
    "    return 2.0 * intersection / (jnp.sum(y_true) + jnp.sum(y_pred) + 1)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def train_step(x, y, train_state, is_training=True):\n",
    "    def loss_fn(params, batch_stats, is_training):\n",
    "        y_pred, batch_stats = train_state.apply_fn_with_bn({\"params\": params, \"batch_stats\": batch_stats}, x,\n",
    "                                                           is_training=is_training)\n",
    "        loss = dice_coef_loss(y, y_pred)\n",
    "\n",
    "        return loss, batch_stats\n",
    "\n",
    "    if is_training:\n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (loss, batch_stats), grads = grad_fn(train_state.params, train_state.batch_stats, True)\n",
    "\n",
    "        train_state = train_state.apply_gradients(grads=grads)\n",
    "        train_state = train_state.update_batch_stats(batch_stats)\n",
    "    else:\n",
    "        loss, batch_stats = loss_fn(train_state.params, train_state.batch_stats, False)\n",
    "\n",
    "    return loss, train_state\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_set = read_train_data()\n",
    "    unet = UNet()\n",
    "\n",
    "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
    "\n",
    "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "\n",
    "    optimizer = optax.adam(learning_rate=0.001)\n",
    "\n",
    "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
    "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
    "\n",
    "    checkpoints.save_checkpoint(ckpt_dir=CKPT_DIR, target=train_state, step=0, overwrite=True)\n",
    "\n",
    "    for e in range(20):\n",
    "        loss_avg = 0\n",
    "        tic = time.time()\n",
    "        for x, y in train_set.as_numpy_iterator():\n",
    "            loss, train_state = train_step(x, y, train_state, True)\n",
    "            loss_avg += loss\n",
    "\n",
    "        loss_avg /= len(train_set)\n",
    "        elapsed = time.time() - tic\n",
    "        print(f\"epoch: {e}, loss: {loss_avg:0.2f}, elapased: {elapsed:0.2f}\")\n",
    "\n",
    "\n",
    "def predict():\n",
    "    data = read_predict_data()\n",
    "    unet = UNet(training=False)\n",
    "\n",
    "    init_rngs = {'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(1)}\n",
    "\n",
    "    unet_variables = unet.init(init_rngs, jnp.ones([1, IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "\n",
    "    optimizer = optax.adam(learning_rate=0.001)\n",
    "\n",
    "    train_state = CustomTrainState.create(apply_fn=unet.apply, params=unet_variables[\"params\"], tx=optimizer,\n",
    "                                          batch_stats=unet_variables[\"batch_stats\"])\n",
    "\n",
    "    checkpoints.restore_checkpoint(ckpt_dir=CKPT_DIR, target=train_state)\n",
    "\n",
    "    pred, _ = train_state.apply_fn_with_bn({\"params\": train_state.params, \"batch_stats\": train_state.batch_stats}, data)\n",
    "\n",
    "    save_image(pred)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d9f2c",
   "metadata": {},
   "source": [
    "## Inference and Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f5d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
